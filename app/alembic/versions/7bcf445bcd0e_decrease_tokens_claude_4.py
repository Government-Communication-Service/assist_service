"""Decrease max tokens in Claude 4

Revision ID: 7bcf445bcd0e
Revises: 37fb0bedbe08
Create Date: 2025-07-08 10:11:42.338811

"""

from typing import Sequence, Union

from alembic import op
from sqlalchemy import MetaData, Table

# revision identifiers, used by Alembic.
revision: str = "7bcf445bcd0e"
down_revision: Union[str, None] = "37fb0bedbe08"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None

model_updates = [
    {
        "model": "anthropic.claude-sonnet-4-20250514-v1:0",
        "max_tokens": 4000,
    },
    {
        "model": "anthropic.claude-opus-4-20250514-v1:0",
        "max_tokens": 4000,
    },
]


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    meta = MetaData()
    meta.reflect(bind=op.get_bind())
    llm_table = Table("llm", meta)
    # Update max_tokens for each model
    for model_update in model_updates:
        op.execute(
            llm_table.update()
            .where(llm_table.c.model == model_update["model"])
            .values(max_tokens=model_update["max_tokens"])
        )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    meta = MetaData()
    meta.reflect(bind=op.get_bind())
    llm_table = Table("llm", meta)
    # Revert max_tokens back to original value (8000)
    for model_update in model_updates:
        op.execute(llm_table.update().where(llm_table.c.model == model_update["model"]).values(max_tokens=8000))
    # ### end Alembic commands ###
